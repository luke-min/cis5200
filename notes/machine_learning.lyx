#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass extarticle
\begin_preamble

\end_preamble
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1.5in
\topmargin 2cm
\rightmargin 1.5in
\bottommargin 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Machine Learning
\end_layout

\begin_layout Author
Luke Min
\end_layout

\begin_layout Abstract
Based on notes from Spring 2024 CIS 5200 at Penn.
\end_layout

\begin_layout Section
Week 1
\end_layout

\begin_layout Subsection
January 18, 2024
\end_layout

\begin_layout Standard
Introduction and Overview
\end_layout

\begin_layout Itemize
Everything is on Canvas
\end_layout

\begin_layout Itemize
CIS 4190/5190: Applied Machine Learning
\end_layout

\begin_layout Itemize
CIS 5450 Big Data Analytics - Data Science.
 Build a machine learning system by yourself, e.g.
 for a startup
\end_layout

\begin_layout Itemize
ESE 5450 Data Mining - Data Science + Math.
 
\end_layout

\begin_layout Standard
You can take CIS 5200 and CIS 5450.
\end_layout

\begin_layout Standard
Prerequisites, Homework 0, etc.
\end_layout

\begin_layout Standard
Grades
\end_layout

\begin_layout Itemize
6HWs (55%), Midterm (20%), Final (25%)
\end_layout

\begin_layout Itemize
Can submit multiple tries for Gradescope.
 Instant feedback for coding assignments.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
What is machine learning?
\end_layout

\begin_layout Itemize
Improve 
\series bold
performance
\end_layout

\begin_layout Itemize
At some 
\series bold
task
\end_layout

\begin_layout Itemize
Given 
\series bold
experience
\end_layout

\begin_layout Standard
Types of Machine Learning
\end_layout

\begin_layout Itemize
Supervised learning
\end_layout

\begin_layout Itemize
Unsupervised learning
\end_layout

\begin_layout Itemize
Semi-supervised
\end_layout

\begin_layout Itemize
Active / Online / Reinforcement Learning, etc....
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Section
Week 2
\end_layout

\begin_layout Subsection
January 23, 2024
\end_layout

\begin_layout Standard
Typical ML Pipeline: Data -> Learning Algorithm -> Knowledge
\end_layout

\begin_layout Itemize
Data: Experience, Training Data
\end_layout

\begin_layout Itemize
Learning: Optimization
\end_layout

\begin_layout Itemize
Knowledge: Performance on some task, a model
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Choices to make
\end_layout

\begin_layout Enumerate
Which Data?
\end_layout

\begin_layout Enumerate
Which Algorithm?
\end_layout

\begin_layout Enumerate
Pick Hyperparameters, estimate
\end_layout

\begin_layout Enumerate
Evaluate or test the model.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Learning Paradigms
\end_layout

\begin_layout Enumerate

\series bold
Supervised Learning
\series default
:
\end_layout

\begin_deeper
\begin_layout Enumerate
Training Data = 
\begin_inset Formula $\left(x_{i},y_{i}\right)=\left(\text{Data},\text{Labels}\right)$
\end_inset


\end_layout

\begin_layout Enumerate
Goal is to train a model that gets labels
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Unsupervised Learning
\series default
:
\end_layout

\begin_deeper
\begin_layout Enumerate
No labels.
 No strict performance metric.
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Semi-Supervised Learning
\end_layout

\begin_deeper
\begin_layout Enumerate
Mix of labelled and unlabelled data.
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Online Learning
\series default
: 
\end_layout

\begin_deeper
\begin_layout Enumerate
Learning by sequentially taking one data point at a time.
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Active Learning
\series default
:
\end_layout

\begin_deeper
\begin_layout Enumerate
You get to choose the next data point you observe.
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Reinforcement Learning
\series default
:
\end_layout

\begin_deeper
\begin_layout Enumerate
Collect their own data, make their own decisions
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Paragraph
Supervised Learning.
\end_layout

\begin_layout Standard
Our notation for the dataset will be 
\begin_inset Formula $\mathcal{D}$
\end_inset

 which we write as
\begin_inset Formula 
\[
\mathcal{D}=\left\{ \left(x_{1},y_{1}\right),\cdots,\left(x_{i},y_{i}\right),\cdots,\left(x_{n},y_{n}\right)\right\} 
\]

\end_inset

Typically the 
\begin_inset Formula $x_{i}\in\mathcal{X}$
\end_inset

 will be 
\series bold
inputs
\series default
, 
\begin_inset Formula $y_{i}\in\mathcal{Y}$
\end_inset

 the 
\series bold
labels
\series default
, and 
\begin_inset Formula $n$
\end_inset

 the number of data points.
 We call 
\begin_inset Formula $\mathcal{X}$
\end_inset

 the 
\series bold
feature space
\series default
 (typically 
\begin_inset Formula $\mathbb{R}^{d}$
\end_inset

) and the 
\begin_inset Formula $\mathcal{Y}$
\end_inset

 the 
\series bold
label space
\series default
.
 
\end_layout

\begin_layout Standard
We will also frequently work with the 
\series bold
feature matrix 
\begin_inset Formula $X$
\end_inset

 
\series default
and the 
\series bold
label vector 
\begin_inset Formula $Y$
\end_inset

 
\series default
which we write as 
\begin_inset Formula 
\[
X=\left[\begin{array}{c}
-x_{1}-\\
-x_{2}-\\
\vdots\\
-x_{n}-
\end{array}\right]\in\mathbb{R}^{n\times d}\quad\text{and}\quad Y=\left[\begin{array}{c}
y_{1}\\
y_{2}\\
\vdots\\
y_{n}
\end{array}\right]\in\mathcal{Y}^{n}
\]

\end_inset


\end_layout

\begin_layout Paragraph
Classification Example: Cat vs.
 Dog.
\end_layout

\begin_layout Standard
In this case, the dataset 
\begin_inset Formula $\mathcal{D}$
\end_inset

 consists of images of cats or dogs (
\begin_inset Formula $x_{i}$
\end_inset

's) and the labels (
\begin_inset Formula $y_{i}$
\end_inset

).
 Here the 
\begin_inset Formula $x_{i}=\text{RGB Pixels}$
\end_inset

.
 If the images are 1000x1000 pixels and RGB has three values, then 
\begin_inset Formula $d=1000\times1000\times3$
\end_inset

.
 The labels could be written as
\begin_inset Formula 
\[
y_{i}=\begin{cases}
+1 & \text{if dog}\\
-1 & \text{if cat}
\end{cases}
\]

\end_inset

This is called a (binary) classification problem.
 In a multi-class classification problem we can say 
\begin_inset Formula 
\[
y_{i}=\begin{cases}
\left(1,0,0\right) & \text{if dog}\\
\left(0,1,0\right) & \text{if cat}\\
\left(0,0,1\right) & \text{if otter}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Paragraph
Regression Example: Housing Prices.
\end_layout

\begin_layout Standard
If you want to build a model that predicts housing prices, the dataset 
\begin_inset Formula $\mathcal{D}$
\end_inset

 consists of descriptors of sold houses, and the price the house sold at.
 
\begin_inset Formula $x_{i}$
\end_inset

 could be number of beds or baths, age, size, and 
\begin_inset Formula $y_{i}$
\end_inset

 could be the price.
 This is called a regression problem.
\end_layout

\begin_layout Paragraph
Measuring Performance with Error.
\end_layout

\begin_layout Standard
A model 
\begin_inset Formula $h:\mathcal{X}\rightarrow\mathcal{Y}$
\end_inset

 is a function from the feature space to the label space, which outputs
 a predicted value 
\begin_inset Formula $\hat{y}=h\left(x\right)$
\end_inset

.
 Thus, for each data 
\begin_inset Formula $x_{i}$
\end_inset

, we want to compare the predicted value 
\begin_inset Formula $\hat{y}_{i}=h\left(x_{i}\right)$
\end_inset

 to the actual value 
\begin_inset Formula $y_{i}$
\end_inset

.
 We write the metric used as 
\begin_inset Formula $\hat{R}$
\end_inset

 for 
\series bold
risk
\series default
 which is
\begin_inset Formula 
\[
\hat{R}_{0/1}\left(h\right)=\frac{1}{n}\sum_{i=1}^{n}l_{0/1}\left(h\left(x_{i}\right),y_{i}\right)
\]

\end_inset

where the 0/1 loss function 
\begin_inset Formula 
\[
l_{0/1}\left(\hat{y}_{i},y_{i}\right)=\begin{cases}
0 & \text{if }\hat{y}=y\\
1 & \text{otherwise }
\end{cases}
\]

\end_inset

This is usually referred to as 
\series bold
training error of 
\begin_inset Formula $h$
\end_inset

.

\series default
 In the case of regression, we can replace the zero one loss with squared
 loss,
\begin_inset Formula 
\[
l_{sq}\left(\hat{y}_{i},y_{i}\right)=\left(\hat{y}_{i}-y_{i}\right)^{2}
\]

\end_inset

All of machine learning is basically trying to estimate 
\begin_inset Formula $h\left(\cdot\right)$
\end_inset

 by minimizing risk.
\end_layout

\begin_layout Paragraph
Generalization Gap.
\end_layout

\begin_layout Standard
Once you estimate 
\begin_inset Formula $h\left(\cdot\right)$
\end_inset

 on training data, we use a separate set of test data to test the the model
 
\begin_inset Formula $h\left(\cdot\right)$
\end_inset

.
 The issue is that our model may not generalize to unseen test data.
 We try to quantify this as the generalization gap which we write as 
\begin_inset Formula $\left|\text{Training Error}-\text{Test Error}\right|$
\end_inset

.
 
\end_layout

\begin_layout Subsection
January 25, 2024
\end_layout

\begin_layout Standard
How do we choose 
\begin_inset Formula $h$
\end_inset

? If we were to minimize training risk, we could always memorize the entire
 training data set by
\begin_inset Formula 
\[
h\left(x\right)=\begin{cases}
y_{i} & \text{if }x=x_{i}\\
1 & \text{otherwise}
\end{cases}
\]

\end_inset

This extreme example leads to the issue of 
\emph on
generalization
\emph default
.
\end_layout

\begin_layout Paragraph
Generalization.
\end_layout

\begin_layout Standard
Suppose we have 
\begin_inset Formula $\left(x_{i},y_{i}\right)\sim\mathcal{P}$
\end_inset

 the training data.
 If in addition we have 
\begin_inset Formula $\left(x,y\right)\sim\mathcal{P}$
\end_inset

 then we can define the 
\series bold
true risk
\series default
 as
\begin_inset Formula 
\[
R\left(h\right)=\mathbb{E}_{\left(x,y\right)\sim\mathcal{P}}\left[l\left(h\left(x\right),y\right)\right]
\]

\end_inset

We want to minimize true risk, not training risk.
 Now we can write
\begin_inset Formula 
\[
R\left(h\right)=\left[\underset{\text{gap}}{\underbrace{R\left(h\right)-\hat{R}\left(h\right)}}\right]+\hat{R}\left(h\right)
\]

\end_inset

Because we want to minimize true risk 
\begin_inset Formula $R\left(h\right)$
\end_inset

, but only observe training risk 
\begin_inset Formula $\hat{R}\left(h\right)$
\end_inset

, one thing we could do is set things up so that generalization bound holds,
 i.e.
 
\begin_inset Formula $R\left(h\right)-\hat{R}\left(h\right)\leq f\left(n\right)$
\end_inset

 where 
\begin_inset Formula $f\left(n\right)\rightarrow0$
\end_inset

 as 
\begin_inset Formula $n\rightarrow\infty$
\end_inset

.
 With infinite data, we can basically close the gap.
 But we return to this later.
\end_layout

\begin_layout Standard
Theoretically, the best we can do is minimize the true risk:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\arg\min_{h}R\left(h\right)=h^{*}
\]

\end_inset

We call this 
\begin_inset Formula $h$
\end_inset

 the 
\series bold
Bayes Optimal Classifier
\series default
.
\end_layout

\begin_layout Paragraph
Example: Binary Classification.
\end_layout

\begin_layout Standard
Let's go through a simple example of binary classification.
 If we know 
\begin_inset Formula 
\[
\eta\left(x\right)=P\left(\left.Y=1\right|x\right)
\]

\end_inset

and use the zero one loss 
\begin_inset Formula $l_{0/1}$
\end_inset

 then we get
\begin_inset Formula 
\begin{align*}
R\left(h\right) & =\mathbb{E}_{\left(x,y\right)\sim\mathcal{P}}\left[l_{0/1}\left(h\left(x\right),y\right)\right]\\
 & =\mathbb{E}_{x}\left[\mathbb{E}_{y|x}\left[l_{0/1}\left(h\left(x\right),y\right)\right]\right]\\
 & =\mathbb{E}_{x}\left[P\left(\left.Y=1\right|x\right)\mathbb{I}\left(h\left(x\right)=-1\right)+P\left(\left.Y=-1\right|x\right)\mathbb{I}\left(h\left(x\right)=1\right)\right]\\
 & =\mathbb{E}_{x}\left[\eta\left(x\right)\mathbb{I}\left(h\left(x\right)=-1\right)+\left(1-\eta\left(x\right)\right)\mathbb{I}\left(h\left(x\right)=1\right)\right]
\end{align*}

\end_inset

In the third line, the 0/1 loss becomes 1 only when h gets the choice wrong.
\end_layout

\begin_layout Standard
The choice of 
\begin_inset Formula $h=h^{*}$
\end_inset

 that minimizes true risk is 
\begin_inset Formula 
\[
h^{*}\left(x\right)=\begin{cases}
-1 & \text{if }\eta\left(x\right)<0.5\\
+1 & \text{otherwise}
\end{cases}
\]

\end_inset

Hence the true risk in this case becomes
\begin_inset Formula 
\[
R\left(h^{*}\right)=\mathbb{E}_{x}\left[\min\left(\eta\left(x\right),1-\eta\left(x\right)\right)\right]
\]

\end_inset

where we assumed the particular distribution 
\begin_inset Formula $\eta\left(x\right)$
\end_inset

 and the loss function 
\begin_inset Formula $l_{0/1}$
\end_inset

.
 
\end_layout

\begin_layout Standard
We call the true risk under Bayes Optimal Classifier the 
\series bold
Bayes Error.
\end_layout

\begin_layout Paragraph
k-Nearest Neighbors.
\end_layout

\begin_layout Standard
Suppose we have X's and O's distributed over some space.
 k-nearest neighbors is an estimator we can use when we 
\emph on
assume that data points close to each other of the same class
\emph default
.
\end_layout

\begin_layout Standard
We take some subset of the training data 
\begin_inset Formula $N_{x}\subseteq\mathcal{D}$
\end_inset

, which we call the neighborhood of 
\begin_inset Formula $x$
\end_inset

.
 Formally we assume that 
\begin_inset Formula $\forall z\in\mathcal{D}\backslash N_{x}$
\end_inset

, 
\begin_inset Formula $z^{\prime}\in N_{x}$
\end_inset

 we have
\begin_inset Formula 
\[
d\left(x,z\right)\geq d\left(x,z^{\prime}\right)
\]

\end_inset

In other words, given some neighborhood of 
\begin_inset Formula $x$
\end_inset

 that we call 
\begin_inset Formula $N_{x}$
\end_inset

, all the points in that neighborhood is close to 
\begin_inset Formula $x$
\end_inset

 than any point outside of it.
\end_layout

\begin_layout Standard
The 
\series bold
k-Nearest Classifier 
\series default
is
\begin_inset Formula 
\[
h\left(x\right)=\text{mode}\left\{ \left.y^{\prime}\right|\left(x^{\prime},y^{\prime}\right)\in N_{x}\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
One key way this might fail is if the differently labelled data points are
 clustered together.
\end_layout

\begin_layout Standard
Another potential issue is that in high dimensional space, the distances
 are very far apart.
 Roughly it might seem like all the points are equally apart, and the KNN
 CLF spits out something that looks like it was randomly chosen.
\end_layout

\begin_layout Standard
Another issue is if our distance function does not capture our distance
 appropriately.
 For example, if we take 
\begin_inset Formula $d\left(x,z\right)=\left\Vert x-z\right\Vert _{2}^{2}$
\end_inset

 or the Euclidean distance, it might not work very well for some form of
 data.
\end_layout

\begin_layout Section
Week 3
\end_layout

\begin_layout Subsection
January 30, 2024 - Perceptron
\end_layout

\begin_layout Standard
Last lecture, we talked about k-nearest neighbors.
 The algorithm builds neighborhoods 
\begin_inset Formula $N_{x}$
\end_inset

 that make the same predictions for labels.
 Issues may arise in: high dimensions (all points seem equidistant) and
 selecting an appropriate notion of a distance (e.g.
 what is a good metric for images?).
\end_layout

\begin_layout Standard
Today we discuss 
\series bold
perceptrons
\series default
, which we build on to get to deep learning.
\end_layout

\begin_layout Standard
Building on k-nearest neighbors, we could instead draw a line that separates
 the space into differently labelled regions.
 We call this a 
\series bold
linear predictor
\series default
.
 Perceptron is an algorithm that helps us find this linear predictor.
\end_layout

\begin_layout Paragraph
Lines.
\end_layout

\begin_layout Standard
Suppose we consider a hyperplane in 
\begin_inset Formula $\mathbb{R}^{d}$
\end_inset

 defined by
\begin_inset Formula 
\[
w^{\top}x+b=0
\]

\end_inset

where 
\begin_inset Formula $x,w\in\mathbb{R}^{d}$
\end_inset

.
 Note 
\begin_inset Formula $w^{\top}x=\left\Vert w\right\Vert \left\Vert x\right\Vert \cos\theta$
\end_inset

.
 
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $w^{\top}x>0$
\end_inset

 then 
\begin_inset Formula $x$
\end_inset

 is on the same side as the region that 
\begin_inset Formula $w$
\end_inset

 is pointing to
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $w^{\top}x<0$
\end_inset

, then 
\begin_inset Formula $x$
\end_inset

 is on the other side.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Hence 
\begin_inset Formula $w$
\end_inset

 basically defines a boundary for 
\begin_inset Formula $x$
\end_inset

's.
 
\end_layout

\begin_layout Paragraph
Linear Model 
\begin_inset Formula $\left(w,b\right)$
\end_inset

.
 
\end_layout

\begin_layout Standard
The linear model for classification is given by where
\begin_inset Formula 
\[
h\left(x\right)=\text{sgn}\left(w^{\top}x+b\right).
\]

\end_inset

The function
\begin_inset Formula 
\[
\text{sgn}\left(a\right)=\begin{cases}
+1 & \text{if }a\geq0\\
-1 & \text{if }a<0
\end{cases}
\]

\end_inset

gives the 
\begin_inset Quotes eld
\end_inset

sign
\begin_inset Quotes erd
\end_inset

 of its argument.
\end_layout

\begin_layout Standard
The linear model retains some helpful properties:
\end_layout

\begin_layout Paragraph
Scale Invariance.
\end_layout

\begin_layout Standard
If we replace the linear model 
\begin_inset Formula $\left(w,b\right)$
\end_inset

 with 
\begin_inset Formula $\left(\alpha w,\alpha b\right)$
\end_inset

 for some 
\begin_inset Formula $\alpha>0$
\end_inset

, nothing changes, as all we care about is the angle.
 So we can set 
\begin_inset Formula $\left\Vert w\right\Vert =1$
\end_inset

.
 
\end_layout

\begin_layout Standard
Suppose we have a dataset 
\begin_inset Formula $\left(x_{i},y_{i}\right)_{i=1}^{m}$
\end_inset

 .
 Let 
\begin_inset Formula $\alpha=\max_{i}\left\Vert x_{i}\right\Vert $
\end_inset

 and normalize 
\begin_inset Formula 
\[
\tilde{x}_{i}=\frac{x_{i}}{\alpha}
\]

\end_inset

which gives us the condition that 
\begin_inset Formula $\left\Vert \tilde{x}_{i}\right\Vert \leq1$
\end_inset

.
 
\end_layout

\begin_layout Standard
In practice, we start by scaling the dataset first to satisfy 
\begin_inset Formula $\left\Vert \tilde{x}_{i}\right\Vert \leq1$
\end_inset

, and then find 
\begin_inset Formula $w$
\end_inset

 in that space.
\end_layout

\begin_layout Paragraph
Bias 
\begin_inset Formula $b$
\end_inset

 is useless.
\end_layout

\begin_layout Standard
Suppose we define new variables as
\begin_inset Formula 
\[
\tilde{x}=\left[\begin{array}{c}
x\\
1
\end{array}\right]\quad\text{and}\quad\tilde{w}=\left[\begin{array}{c}
w\\
b
\end{array}\right]
\]

\end_inset

which gives us 
\begin_inset Formula $\tilde{w}^{\top}\tilde{x}=w^{\top}x+b=0$
\end_inset

.
 The tilde transformation adds an extra dimension, and slides the whole
 plane down by 
\begin_inset Formula $b$
\end_inset

.
 Now in this new space, the 
\begin_inset Formula $\tilde{x}$
\end_inset

 goes through the origin.
 This tells us that we can always redefine the problem so that the relevant
 subspace goes through the origin.
\end_layout

\begin_layout Paragraph
Margin 
\begin_inset Formula $\gamma$
\end_inset

.
 
\end_layout

\begin_layout Standard
In words, the margin 
\begin_inset Formula $\gamma$
\end_inset

 is defined as the minimum distance of 
\begin_inset Formula $x_{i}$
\end_inset

 to the line defined by 
\begin_inset Formula $w$
\end_inset

:
\begin_inset Formula 
\[
\gamma\coloneqq\min_{i}\left|w^{\top}x_{i}\right|
\]

\end_inset

This means that given a linear model 
\begin_inset Formula $\left(w,b\right)$
\end_inset

 if we have margin 
\begin_inset Formula $\gamma$
\end_inset

, there are no points within 
\begin_inset Formula $\gamma$
\end_inset

 distance of the linear model.
\end_layout

\begin_layout Standard
The margin shows how much room you have on either side, and tells you how
 much space for errors you have.
 If the classifier has a good margin, then its a good classifier.
 If the margin is very small, then its a challenging problem.
\end_layout

\begin_layout Paragraph
\begin_inset Formula $y_{i}w^{\top}x_{i}>0$
\end_inset

.
\end_layout

\begin_layout Standard
If the sign of 
\begin_inset Formula $y_{i}$
\end_inset

 and 
\begin_inset Formula $w^{\top}x_{i}$
\end_inset

 are the same, then we have 
\begin_inset Formula $y_{i}w^{\top}x_{i}>0$
\end_inset

.
 In other words, we have 
\begin_inset Formula $y_{i}w^{\top}x_{i}>0$
\end_inset

 when the prediction is correct.
 Hence we can use the quantity 
\begin_inset Formula $y_{i}w^{\top}x_{i}$
\end_inset

 to proxy for correctness.
 If the quantity is very large and positive, then we are very far from the
 margin, and we are quite sure about that point; if it's very negative,
 then we place a lot of confidence that it's correct, but it is in fact
 incorrect.
\end_layout

\begin_layout Paragraph
Perceptron.
\end_layout

\begin_layout Standard
We first state the assumption behind the perceptron algorithm.
\end_layout

\begin_layout Standard
The realizability / Linear Separability assumption: 
\begin_inset Formula $\exists w_{*}$
\end_inset

 such that 
\begin_inset Formula $\forall x_{i}$
\end_inset

, 
\begin_inset Formula $y_{i}w_{*}^{\top}x_{i}>0$
\end_inset

.
 
\begin_inset Formula $\gamma_{w^{*}}=\gamma$
\end_inset

.
 This assumes that there is some 
\begin_inset Quotes eld
\end_inset

perfect
\begin_inset Quotes erd
\end_inset

 classifier.
\end_layout

\begin_layout Standard
Here's the algorithm:
\end_layout

\begin_layout Enumerate
Start with 
\begin_inset Formula $w_{0}=0$
\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $t=1,2,\cdots$
\end_inset

 find 
\begin_inset Formula $i$
\end_inset

 such that 
\begin_inset Formula $y_{i}w_{t}^{\top}x_{i}\leq0$
\end_inset

.
 Update 
\begin_inset Formula $w_{t+1}=w_{t}+y_{i}x_{i}$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
Repeat.
 If None, break.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Why does this algorithm work? Assume 
\begin_inset Formula $\left\Vert x_{i}\right\Vert =1$
\end_inset

.
 If we get that 
\begin_inset Formula $y_{i}w_{t}^{\top}x_{i}\leq0$
\end_inset

, that means we got that point wrong.
 And as we update,
\begin_inset Formula 
\[
w_{t+1}=w_{t}+y_{i}x_{i}
\]

\end_inset

so that 
\begin_inset Formula 
\begin{align*}
w_{t+1}^{\top}x_{i} & =\left(w_{t}+y_{i}x_{i}\right)^{\top}x_{i}\\
 & =w_{t}^{\top}x_{i}+y_{i}\left\Vert x_{i}\right\Vert ^{2}\\
 & =\begin{cases}
w_{t}^{\top}x_{i}+\left\Vert x_{i}\right\Vert ^{2} & \text{if }y_{i}>0\\
w_{t}^{\top}x_{i}-\left\Vert x_{i}\right\Vert ^{2} & \text{if }y_{i}<0
\end{cases}
\end{align*}

\end_inset

Closely observe the above under two cases.
 First, when 
\begin_inset Formula $y_{i}=+1$
\end_inset

, then, 
\begin_inset Formula $w_{t}^{\top}x_{i}\leq0$
\end_inset

, and updating the 
\begin_inset Formula $w$
\end_inset

 this way 
\begin_inset Quotes eld
\end_inset

adds
\begin_inset Quotes erd
\end_inset

 to 
\begin_inset Formula $w_{t}$
\end_inset

 so that it is now closer to being positive (which was the correct prediction).
 Similarly, the opposite holds for 
\begin_inset Formula $y_{i}=-1$
\end_inset

.
 Since we got it wrong (
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $y_{i}w_{t}^{\top}x_{i}\leq0$
\end_inset


\begin_inset Quotes erd
\end_inset

), this means 
\begin_inset Formula $w_{t}^{\top}x_{i}\geq0$
\end_inset

, and we need to bring it down somehow.
 That's what happens in the updating step.
\end_layout

\begin_layout Standard
Adding a wrong point and updating 
\begin_inset Formula $w$
\end_inset

 rotates the whole 
\begin_inset Formula $w$
\end_inset

 to the 
\begin_inset Quotes eld
\end_inset

correct
\begin_inset Quotes erd
\end_inset

 place.
\end_layout

\begin_layout Paragraph
Convergence Proof.
\end_layout

\begin_layout Standard
A measure of closeness to 
\begin_inset Formula $w_{*}$
\end_inset

 is given by 
\begin_inset Formula $w_{*}^{\top}w_{t}$
\end_inset

.
 So that can increase if either (1) the angle is getting smaller; or (2)
 norm of 
\begin_inset Formula $w_{t}$
\end_inset

 is getting larger.
 So a better measure is
\begin_inset Formula 
\[
\frac{w_{*}^{\top}w_{t}}{\left\Vert w_{t}\right\Vert }=\cos\theta_{t}
\]

\end_inset

 Now given an update at 
\begin_inset Formula $t,$
\end_inset

 substitute
\begin_inset Formula 
\begin{align*}
w_{*}^{\top}w_{t} & =w_{*}^{\top}\left(w_{t-1}+y_{i}x_{i}\right)\\
 & =w_{*}^{\top}w_{t-1}+y_{i}\left(w_{*}^{\top}x_{i}\right)
\end{align*}

\end_inset

Note 
\begin_inset Formula $y_{i}\left(w_{*}^{\top}x_{i}\right)>0$
\end_inset

 since 
\begin_inset Formula $w_{*}$
\end_inset

 is a perfect classifier.
 We also know 
\begin_inset Formula $\left|w_{*}^{\top}x_{i}\right|\geq\gamma$
\end_inset

.
 So we have
\begin_inset Formula 
\begin{align*}
w_{*}^{\top}w_{t} & \geq w_{*}^{\top}w_{t-1}+\gamma\\
 & \geq w_{*}^{\top}w_{t-2}+2\gamma\\
 & \vdots\\
 & \geq\underset{w_{0}\coloneqq0}{\underbrace{w_{*}^{\top}w_{0}}}+t\gamma=t\gamma
\end{align*}

\end_inset

Thus we conclude
\begin_inset Formula 
\[
w_{*}^{\top}w_{t}\geq t\gamma
\]

\end_inset


\end_layout

\begin_layout Standard
Now we need to show the denominator is not increasing too fast.
 The denominator is
\begin_inset Formula 
\begin{align*}
\left\Vert w_{t}\right\Vert ^{2} & =w_{t}^{\top}w_{t}\\
 & =\left(w_{t-1}+y_{i}x_{i}\right)^{\top}\left(w_{t-1}+y_{i}x_{i}\right)\\
 & =\underset{=\left\Vert w_{t-1}\right\Vert ^{2}}{\underbrace{w_{t-1}^{\top}w_{t-1}}}+2\underset{<0}{\underbrace{y_{i}\left(w_{t-1}^{\top}x_{i}\right)}}+\underset{\leq1}{\underbrace{y_{i}^{2}\left(x_{i}^{\top}x_{i}\right)}}\\
 & \leq\left\Vert w_{t-1}\right\Vert ^{2}+1
\end{align*}

\end_inset

Note 
\begin_inset Formula $y_{i}\left(w_{t-1}^{\top}x_{i}\right)<0$
\end_inset

 because we always pick the 
\begin_inset Quotes eld
\end_inset

incorrectly predicted points
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $i$
\end_inset

 to update the 
\begin_inset Formula $w$
\end_inset

.
 We have 
\begin_inset Formula $y_{i}^{2}\left(x_{i}^{\top}x_{i}\right)\leq1$
\end_inset

 because 
\begin_inset Formula $y_{i}^{2}=1$
\end_inset

 and the norm of 
\begin_inset Formula $x_{i}$
\end_inset

 is bounded above by 1 by construction.
\end_layout

\begin_layout Standard
Continuing we get that
\begin_inset Formula 
\begin{align*}
\left\Vert w_{t}\right\Vert ^{2} & \leq\left\Vert w_{t-1}\right\Vert ^{2}+1\\
 & \leq\left\Vert w_{t-2}\right\Vert ^{2}+2\\
 & \vdots\\
 & \leq\left\Vert w_{0}\right\Vert ^{2}+t\\
 & =t
\end{align*}

\end_inset

Now collecting our two conditions, we have
\begin_inset Formula 
\[
w_{*}^{\top}w_{t}\geq t\gamma\quad\text{and}\quad\left\Vert w_{t}\right\Vert ^{2}\leq t
\]

\end_inset

Going back to our angle definition,
\begin_inset Formula 
\begin{align*}
\cos\theta_{t} & =\frac{w_{*}^{\top}w_{t}}{\left\Vert w_{t}\right\Vert }=\frac{\geq\gamma t}{\leq t}\\
 & \geq\frac{\gamma t}{\sqrt{t}}=\gamma\sqrt{t}
\end{align*}

\end_inset

Now since cosine is bounded, we get that
\begin_inset Formula 
\[
1\geq\gamma\sqrt{t}
\]

\end_inset

so that
\begin_inset Formula 
\[
t\leq\frac{1}{\gamma^{2}}
\]

\end_inset


\end_layout

\begin_layout Paragraph
Caveats.
\end_layout

\begin_layout Standard
When we define an algorithm, it's good to understand when it fails.
\end_layout

\begin_layout Itemize
When we have the realizability assumption fail, then the algorithm fails.
\end_layout

\begin_layout Itemize
When we have differently labelled data points in each region (
\begin_inset Quotes eld
\end_inset

XOR Problem
\begin_inset Quotes erd
\end_inset

) it fails the assumption, and the algo doesn't work.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsection
February 1, 2024 - Gradient Descent
\end_layout

\begin_layout Paragraph
Recap of Perceptron.
\end_layout

\begin_layout Standard
Recall the perceptron algorithm:
\end_layout

\begin_layout Enumerate
Set 
\begin_inset Formula $w_{0}=0$
\end_inset

.
\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $t=1,2,\cdots$
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
if 
\begin_inset Formula $\exists i$
\end_inset

 such that 
\begin_inset Formula $y_{i}w_{t}^{\top}x_{i}\leq0$
\end_inset

 then 
\begin_inset Formula $w_{t+1}=w_{t}+y_{i}x_{i}$
\end_inset


\end_layout

\begin_layout Enumerate
else break
\end_layout

\end_deeper
\begin_layout Standard
Key takeaways of the perceptron algorithm:
\end_layout

\begin_layout Enumerate
We require that 
\begin_inset Formula $\exists w_{*}$
\end_inset

 such that 
\begin_inset Formula $\forall i$
\end_inset

, 
\begin_inset Formula $y_{i}w_{*}^{\top}x_{i}\geq0$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
Define the margin as
\begin_inset Formula 
\[
\gamma=\min_{i}\left|w_{*}^{\top}x_{i}\right|
\]

\end_inset

where we assume that 
\begin_inset Formula $\left\Vert w_{*}\right\Vert =1$
\end_inset

.
 The guarantee is that if you run the perceptron algorithm, it will terminate
 after at most 
\begin_inset Formula $1/\gamma^{2}$
\end_inset

 steps.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Note that it's possible to have 
\begin_inset Formula $\gamma=0$
\end_inset

, and the guarantee could in theory be a terrible one.
 This algorithm, just like KNN, relies on the 
\begin_inset Quotes eld
\end_inset

geometry
\begin_inset Quotes erd
\end_inset

 of the problem.
 It's very specific to the structure of the problem, whereas other algorithms
 are more general purpose, like gradient descent.
\end_layout

\begin_layout Paragraph
Overview.
\end_layout

\begin_layout Standard
Today we discuss the 
\series bold
gradient descent
\series default
, one of the most successful algorithms in machine learning.
 A lot of modern machine learning applications utilize a version of gradient
 descent.
 It works surprisingly well even in contexts where you wouldn't expect it
 to perform that well.
 We will see that even the perceptron algorithm that we saw last lecture
 is the same as gradient descent under appropriately defined objective functions.
\end_layout

\begin_layout Paragraph
What is our goal?
\end_layout

\begin_layout Standard
Recall that we have the empirical risk
\begin_inset Formula 
\[
\min_{h}\hat{R}\left(h\right)=\frac{1}{n}\sum_{i=1}^{n}l\left(h\left(x_{i}\right),y_{i}\right)
\]

\end_inset

where 
\begin_inset Formula $h$
\end_inset

 is the model and 
\begin_inset Formula $l$
\end_inset

 is the loss function.
 We considered two different loss functions.
 First the zero-one loss for classification:
\begin_inset Formula 
\[
l_{0/1}\left(\hat{y},y\right)=\begin{cases}
0 & y=\hat{y}\\
1 & \text{otherwise}
\end{cases}
\]

\end_inset

And least squares loss for regression
\begin_inset Formula 
\[
l_{sq}\left(\hat{y},y\right)=\frac{1}{2}\left(\hat{y}-y\right)^{2}
\]

\end_inset


\end_layout

\begin_layout Paragraph
Function Class 
\begin_inset Formula $H$
\end_inset


\end_layout

\begin_layout Standard
What are the function classes we consider? Note for the linear models we
 had
\begin_inset Formula 
\[
H=\left\{ x\mapsto w^{\top}x+b\right\} 
\]

\end_inset

so mapping this to the minimization problem we get
\begin_inset Formula 
\[
\min_{w,b}\frac{1}{n}\sum_{i=1}^{n}l\left(w^{\top}x_{i}+b,y_{i}\right)
\]

\end_inset

This process of restricting our function class 
\begin_inset Formula $H$
\end_inset

 is called 
\series bold
parametrization
\series default
.
 Now the problem becomes more concrete! For a lot of loss functions, we
 can optimize this!
\end_layout

\begin_layout Paragraph
General Setup
\end_layout

\begin_layout Standard
A more general setup would be
\begin_inset Formula 
\begin{align*}
 & \min_{w}F\left(w\right)\\
\text{such that}\quad & w\in C
\end{align*}

\end_inset

 where 
\begin_inset Formula $F$
\end_inset

 is the objective; 
\begin_inset Formula $C$
\end_inset

 is the constraint set; and 
\begin_inset Formula $w$
\end_inset

 is our choice variable.
 How can we solve this?
\end_layout

\begin_layout Standard
Let's pretend for now that 
\begin_inset Formula $F$
\end_inset

 is simple.
 For instance, for small 
\begin_inset Formula $v$
\end_inset

 we can approximate linearly as in a Taylor approximation:
\begin_inset Formula 
\[
F\left(w+v\right)\approx F\left(w\right)+\underset{\text{gradient}}{\underbrace{\nabla F\left(w\right)^{\top}}}v
\]

\end_inset

Here we are assuming that 
\begin_inset Formula $F\left(\cdot\right)$
\end_inset

 is 
\emph on
locally linear
\emph default
.
 This is the general idea of gradient descent.
\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $F\left(w+v\right)\leq F\left(w\right)$
\end_inset

.
 Then
\begin_inset Formula 
\begin{align*}
F\left(w+v\right) & =F\left(w\right)+\nabla F\left(w\right)^{\top}v\\
 & =F\left(w\right)+\nabla F\left(w\right)^{\top}\left(-\eta\nabla F\left(w\right)\right)\\
 & =F\left(w\right)-\eta\left\Vert \nabla F\left(w\right)\right\Vert ^{2}
\end{align*}

\end_inset

where we used 
\begin_inset Formula $v=-\eta\nabla F\left(w\right)$
\end_inset

, which guarantees 
\begin_inset Formula $-\eta\left\Vert \nabla F\left(w\right)\right\Vert ^{2}\leq0$
\end_inset

.
\end_layout

\begin_layout Paragraph
Gradient Descent.
\end_layout

\begin_layout Standard
Here we present the graident descent algorithm:
\end_layout

\begin_layout Enumerate
Set 
\begin_inset Formula $w_{0}\in\mathbb{R}^{d}$
\end_inset

.
\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $t=1,2,\cdots,T$
\end_inset

 
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $w_{t+1}=w_{t}-\eta\nabla F\left(w_{t}\right)$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $F\left(w_{t+1}\right)=F\left(w_{t}\right)-\eta\left\Vert \nabla F\left(w_{t}\right)\right\Vert ^{2}$
\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate
Stop when 
\begin_inset Formula $\left\Vert \nabla F\left(w\right)\right\Vert \leq\epsilon$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Note that 
\begin_inset Formula 
\begin{align*}
F\left(w_{t+1}\right) & =F\left(w_{t}-\eta\nabla F\left(w_{t}\right)\right)\\
 & =F\left(w_{t}\right)+\nabla F\left(w_{t}\right)^{\top}\left(-\eta\nabla F\left(w_{t}\right)\right)\\
 & =F\left(w_{t}\right)-\eta\left\Vert \nabla F\left(w_{t}\right)\right\Vert ^{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
How should we choose the 
\series bold
learning rate
\series default
 
\begin_inset Formula $\eta$
\end_inset

? If it is too large, it will 
\begin_inset Quotes eld
\end_inset

jump over
\begin_inset Quotes erd
\end_inset

 the minimum point and miss it, and result in 
\series bold
divergence
\series default
.
 If it is too small, the learning will take too long.
 There are a number of strategies people have taken.
\end_layout

\begin_layout Itemize
Take a big first step, and then take many small steps.
\end_layout

\begin_layout Itemize
Start with a big 
\begin_inset Formula $\eta$
\end_inset

, and then decrease it over time by setting 
\begin_inset Formula $\eta_{t+1}=0.99\eta_{t}$
\end_inset

.
 
\end_layout

\begin_layout Itemize
Transformers increase 
\begin_inset Formula $\eta$
\end_inset

 in the beginning, keep it at that max for a while, and then linearly decrease
 it.
\end_layout

\begin_layout Itemize
etc..
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Paragraph
Limitations of Gradient Descent.
\end_layout

\begin_layout Standard
In what settings will gradient descent struggle to perform?
\end_layout

\begin_layout Itemize
Whenever the function 
\begin_inset Formula $F\left(\cdot\right)$
\end_inset

 is 
\begin_inset Quotes eld
\end_inset

flat
\begin_inset Quotes erd
\end_inset

 for some regions, the algorithm will get struck.
\end_layout

\begin_layout Itemize
When we have local minima, it will also get stuck there.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
In general, when we stop making 
\begin_inset Quotes eld
\end_inset

local progress
\begin_inset Quotes erd
\end_inset

 the algorithm will terminate, i.e.
 
\begin_inset Formula $\nabla F\left(w_{t}\right)\approx0$
\end_inset

.
 This can happen at (i) local minimum, (ii) local maxima, (iii) saddle point.
 But what we want is the global minima.
\end_layout

\begin_layout Standard
For this class, we will assume there is a global minimum.
 In case of quadratic functions, this will be true.
\end_layout

\begin_layout Standard
In cases of non-differentiable functions, we can use sub-gradients.
 But for this class, we won't use it.
 For instance
\begin_inset Formula 
\[
\text{ReLu}\left(x\right)=\max\left(w^{\top}x,0\right)
\]

\end_inset

is used a lot it neural networks.
 
\end_layout

\begin_layout Paragraph
Perceptron and Gradient Descent
\end_layout

\begin_layout Standard
Consider the loss function
\begin_inset Formula 
\[
l\left(\hat{y},y\right)=\max\left(-\hat{y}y,0\right)
\]

\end_inset

If you run this gradient descent with 
\begin_inset Formula $\eta=1$
\end_inset

, then you get the perceptron algorithm.
 
\end_layout

\begin_layout Standard
What's happening here? 
\begin_inset Formula $\hat{y}y>0$
\end_inset

 when we get the correct prediction, in which case the max function is binding
 and loss is zero.
 On the other hand, 
\begin_inset Formula $\hat{y}y<0$
\end_inset

 when we predict wrongly, and the loss is equal to 
\begin_inset Formula $-\hat{y}y$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
Second Order Approximation.
\end_layout

\begin_layout Standard
Consider the first and second order approximations:
\end_layout

\begin_layout Enumerate
\begin_inset Formula $F\left(w+v\right)\approx F\left(w\right)+\nabla F\left(w\right)^{\top}v$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $F\left(w+v\right)\approx F\left(w\right)+\nabla F\left(w\right)^{\top}v+\frac{1}{2}v^{\top}Hv$
\end_inset

 where 
\begin_inset Formula $H_{ij}=\frac{\partial^{2}F}{\partial w_{i}\partial w_{j}}$
\end_inset

 is the Hessian
\end_layout

\begin_layout Standard
How should we proceed in the second case? Take the derivative with respect
 to 
\begin_inset Formula $v$
\end_inset

 to obtain
\begin_inset Formula 
\[
\nabla F\left(w\right)+Hv=0
\]

\end_inset

or that
\begin_inset Formula 
\[
v=-H^{-1}\nabla F\left(w\right)
\]

\end_inset

An algorithm that uses this is called the 
\series bold
Newton's Method
\series default
.
 Now we no longer have the learning rate 
\begin_inset Formula $\eta$
\end_inset

.
\end_layout

\begin_layout Paragraph
Newton's Method.
\end_layout

\begin_layout Standard
Here's the actual algorithm.
\end_layout

\begin_layout Enumerate
Set 
\begin_inset Formula $w_{1}\in\mathbb{R}^{d}$
\end_inset


\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $t=1,\cdots,T$
\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $w_{t+1}=w_{t}-H^{-1}\nabla F\left(w_{t}\right)$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
This works really well if the function is actually close to quadratic.
 If it's exactly quadratic, then this gets you the solution in a single
 step.
\end_layout

\begin_layout Standard
The cost is that we now have to compute the Hessian, and then invert it.
 In high dimensions, this becomes quite costly.
 This is why in many cases we just use the gradient descent in practice.
\end_layout

\begin_layout Paragraph
When to Use Gradient Descent.
\end_layout

\begin_layout Standard
When is it a good idea to use gradient descent?
\end_layout

\begin_layout Itemize
When the function is convex
\end_layout

\begin_layout Itemize
When the function is smooth i.e.
 if 
\begin_inset Formula $v$
\end_inset

 is small then 
\begin_inset Formula $\left|f\left(w+v\right)-f\left(w\right)\right|$
\end_inset

 is small.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Paragraph
Convexity.
\end_layout

\begin_layout Standard
When we restrict ourselves to a certain class of functions, then we can
 make some guarantees about the performan ce of gradient descent.
 
\series bold
Convex functions 
\series default
is an important one, and there are a number of definitions.
 Here's one.
\end_layout

\begin_layout Standard
A function 
\begin_inset Formula $F$
\end_inset

 is 
\series bold
convex
\series default
 if for all 
\begin_inset Formula $\alpha\in\left[0,1\right]$
\end_inset

 and for all 
\begin_inset Formula $w,w^{\prime}\in\mathbb{R}^{d}$
\end_inset

,
\begin_inset Formula 
\[
F\left(\alpha w+\left(1-\alpha\right)w^{\prime}\right)\leq\alpha F\left(w\right)+\left(1-\alpha\right)F\left(w^{\prime}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $F$
\end_inset

 is differentiable, then 
\begin_inset Formula $F$
\end_inset

 is convex if for all 
\begin_inset Formula $w,w^{\prime}\in\mathbb{R}^{d}$
\end_inset

,
\begin_inset Formula 
\[
F\left(w^{\prime}\right)\geq F\left(w\right)+\nabla F\left(w\right)^{\top}\left(w^{\prime}-w\right)
\]

\end_inset

If 
\begin_inset Formula $F$
\end_inset

 is twice differentiable, then we require
\begin_inset Formula 
\[
\nabla^{2}F\left(w\right)\succeq0
\]

\end_inset

or that the Hessian is the positive semi-definite.
 The Hessian is the rate of change of the gradient.
 
\end_layout

\begin_layout Section
Week 4
\end_layout

\begin_layout Subsection
February 6, 2024 - Gradient Descent, Empirical Risk Minimization
\end_layout

\begin_layout Paragraph
Quick Recap.
\end_layout

\begin_layout Standard
In gradient descent, the goal is to learn a model 
\begin_inset Formula $h\left(\cdot\right)$
\end_inset

 as follows:
\end_layout

\begin_layout Enumerate
Pick some parameterized 
\begin_inset Formula $h$
\end_inset

.
 For example, take 
\begin_inset Formula $h\left(x\right)=w^{\top}x+b$
\end_inset

 linear.
\end_layout

\begin_layout Enumerate
Start with some 
\begin_inset Formula $w_{1}\in\mathbb{R}^{d}$
\end_inset

 .
\end_layout

\begin_layout Enumerate
For 
\begin_inset Formula $t=1,2,\cdots$
\end_inset

, compute 
\begin_inset Formula $w_{t+1}=w_{t}-\eta_{t}\nabla F\left(w_{t}\right)$
\end_inset

 for some loss 
\begin_inset Formula $F\left(\cdot\right)$
\end_inset

.
\end_layout

\begin_layout Standard
This works well under certain assumptions like convexity, which has several
 definitions:
\end_layout

\begin_layout Enumerate
(General) 
\begin_inset Formula $F\left(\alpha w^{\prime}+\left(1-\alpha\right)w\right)\leq\alpha F\left(w^{\prime}\right)+\left(1-\alpha\right)F\left(w\right)$
\end_inset

 for all 
\begin_inset Formula $w,w^{\prime}\in\mathbb{R}^{d}$
\end_inset

 and 
\begin_inset Formula $\alpha\in\left[0,1\right]$
\end_inset

.
\end_layout

\begin_layout Enumerate
(
\begin_inset Formula $F$
\end_inset

 is differentiable) 
\begin_inset Formula $F\left(w^{\prime}\right)\geq F\left(w\right)+\nabla F\left(w\right)^{\top}\left(w^{\prime}-w\right)$
\end_inset


\end_layout

\begin_layout Enumerate
(F is twice differentiable) 
\begin_inset Formula $\nabla^{2}F\left(w\right)\succeq0$
\end_inset

 (i.e.
 PSD), or for all non-zero 
\begin_inset Formula $v\in\mathbb{R}^{d}$
\end_inset

, 
\begin_inset Formula $v^{\top}\nabla^{2}F\left(w\right)v\geq0$
\end_inset

, or Hessian has non-negative eigenvalues.
\end_layout

\begin_layout Standard
A second property to keep in mind is L-smoothness.
 A function is smooth if its gradient does not change too fast.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\left\Vert \nabla F\left(w\right)-\nabla F\left(w^{\prime}\right)\right\Vert \leq L\left\Vert w-w^{\prime}\right\Vert $
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $F\left(w^{\prime}\right)\leq F\left(w\right)+\nabla F\left(w\right)^{\top}\left(w^{\prime}-w\right)+\frac{L}{2}\left\Vert w^{\prime}-w\right\Vert ^{2}$
\end_inset


\end_layout

\begin_layout Standard
The first condition essentially claims that if the inputs 
\begin_inset Formula $w$
\end_inset

 and 
\begin_inset Formula $w^{\prime}$
\end_inset

 are quite close, then the gradient also has to be sufficiently close.
 When 
\begin_inset Formula $L$
\end_inset

 is large, then the function is 
\emph on
less smooth
\emph default
.
 If 
\begin_inset Formula $L=0$
\end_inset

 for instance, then the gradient stays the same.
 We pick the smallest 
\begin_inset Formula $L$
\end_inset

 such that this condition is true for all 
\begin_inset Formula $w,w^{\prime}\in\mathbb{R}^{d}$
\end_inset

.
 If a function is 2-smooth, then it's also 10-smooth.
\end_layout

\begin_layout Standard
The second condition basically says the function should lie below a quadratic
 term.
 The function is upper bounded by some quadratic term.
 Constant 
\begin_inset Formula $L$
\end_inset

 modulates how quadratic that second term is.
\end_layout

\begin_layout Standard
If we combine convexity and smoothness, it provides both some upper bound
 and some lower bound, 
\begin_inset Quotes eld
\end_inset

sandwiching
\begin_inset Quotes erd
\end_inset

 the function.
\end_layout

\begin_layout Standard
Strong convexity is like the opposite of smoothness.
 It says that the function's gradient should change by at least some rate,
 and says the function should have some curvature (i.e.
 it can't just be flat).
\end_layout

\begin_layout Standard
Now we present a theorem on the convergence of the gradient descent algorithm:
\end_layout

\begin_layout Theorem
For a L-smooth convex function 
\begin_inset Formula $F$
\end_inset

, gradient descent with 
\begin_inset Formula $\eta_{t}=1/L$
\end_inset

, we have
\begin_inset Formula 
\[
F\left(w_{t+1}\right)-F\left(w_{*}\right)\leq\frac{L}{2t}\left\Vert w_{1}-w_{*}\right\Vert ^{2}
\]

\end_inset

where 
\begin_inset Formula $w_{*}$
\end_inset

 is the optimal value.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
This theorem says that our distant to the optimal value at iteration 
\begin_inset Formula $t+1$
\end_inset

, given by 
\begin_inset Formula $F\left(w_{t+1}\right)-F\left(w_{*}\right)$
\end_inset

, can be bounded above.
 Let say we want the bound to be 
\begin_inset Formula $\epsilon$
\end_inset

 so that 
\begin_inset Formula $\frac{L}{2t}\left\Vert w_{1}-w_{*}\right\Vert ^{2}\le\epsilon$
\end_inset

.
 Then note that we need
\begin_inset Formula 
\[
t=\frac{L}{2\epsilon}\left\Vert w_{1}-w_{*}\right\Vert ^{2}
\]

\end_inset

The algorithm itself does not depend on 
\begin_inset Formula $w_{*}$
\end_inset

, but this theorem gives us some form of theoretical guarantee for convergence.
\end_layout

\begin_layout Proof
First, we begin by showing 
\begin_inset Formula $F\left(w_{t+1}\right)\leq F\left(w_{t}\right)$
\end_inset

.
 Use the update condition given by
\begin_inset Formula 
\[
w_{t+1}=w_{t}-\frac{1}{L}\nabla F\left(w_{t}\right)
\]

\end_inset

for 
\begin_inset Formula $\eta=1/L$
\end_inset

.
 Smoothness gives us 
\begin_inset Formula 
\begin{align*}
F\left(w_{t+1}\right) & \leq F\left(w_{t}\right)+\nabla F\left(w_{t}\right)^{\top}\left(w_{t+1}-w_{t}\right)+\frac{L}{2}\left\Vert w_{t+1}-w_{t}\right\Vert ^{2}\\
 & =F\left(w_{t}\right)-L\left(w_{t+1}-w_{t}\right)^{\top}\left(w_{t+1}-w_{t}\right)+\frac{L}{2}\left\Vert w_{t+1}-w_{t}\right\Vert ^{2}\\
 & =F\left(w_{t}\right)-\frac{L}{2}\left\Vert w_{t+1}-w_{t}\right\Vert ^{2}
\end{align*}

\end_inset

We want to get rid of the gradient term, so we substitute the rearrange
 update condition 
\begin_inset Formula $L\left(w_{t+1}-w_{t}\right)=-\nabla F\left(w_{t}\right)$
\end_inset

 in the second line.
 This tells us that we will be decreasing the function at each iteration.
\end_layout

\begin_layout Proof
Second, we want to show how close we are getting to the minimizer 
\begin_inset Formula $w_{*}$
\end_inset

, i.e.
 
\begin_inset Formula $w_{t}$
\end_inset

 is getting closer to 
\begin_inset Formula $w_{*}$
\end_inset

.
 We use the definition of convexity on 
\begin_inset Formula $w_{*}$
\end_inset

 and 
\begin_inset Formula $w_{t}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
F\left(w_{*}\right) & \geq F\left(w_{t}\right)+\nabla F\left(w_{t}\right)^{\top}\left(w_{*}-w_{t}\right)\\
 & =F\left(w_{t}\right)-L\left(w_{t+1}-w_{t}\right)^{\top}\left(w_{*}-w_{t}\right)\\
 & =F\left(w_{t}\right)+\frac{L}{2}\left[\left\Vert w_{t+1}-w_{*}\right\Vert ^{2}-\left\Vert w_{t}-w_{t+1}\right\Vert ^{2}-\left\Vert w_{t}-w_{*}\right\Vert ^{2}\right]
\end{align*}

\end_inset

where we complete the square
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Let 
\begin_inset Formula $a=w_{t+1}-w_{t}$
\end_inset

 and 
\begin_inset Formula $b=-\left(w_{*}-w_{t}\right)$
\end_inset

 so that 
\begin_inset Formula 
\begin{align*}
2a^{\top}b & =\left\Vert a+b\right\Vert ^{2}-\left\Vert a\right\Vert ^{2}-\left\Vert b\right\Vert ^{2}\\
 & =\left\Vert \left(w_{t+1}-w_{t}\right)-\left(w_{*}-w_{t}\right)\right\Vert ^{2}-\left\Vert \left(w_{t+1}-w_{t}\right)\right\Vert ^{2}-\left\Vert -\left(w_{*}-w_{t}\right)\right\Vert ^{2}\\
 & =\left\Vert w_{t+1}-w_{*}\right\Vert ^{2}-\left\Vert w_{t+1}-w_{t}\right\Vert ^{2}-\left\Vert w_{t}-w_{*}\right\Vert ^{2}
\end{align*}

\end_inset


\end_layout

\end_inset

 using 
\begin_inset Formula $2a^{\top}b=\left\Vert a+b\right\Vert ^{2}-\left\Vert a\right\Vert ^{2}-\left\Vert b\right\Vert ^{2}$
\end_inset

.
 
\end_layout

\begin_layout Proof
Now we combine the two results:
\begin_inset Formula 
\begin{align*}
F\left(w_{t+1}\right) & \leq F\left(w_{t}\right)-\frac{L}{2}\left\Vert w_{t+1}-w_{t}\right\Vert ^{2}\\
-F\left(w_{*}\right) & \leq-F\left(w_{t}\right)-\frac{L}{2}\left[\left\Vert w_{t+1}-w_{*}\right\Vert ^{2}-\left\Vert w_{t}-w_{t+1}\right\Vert ^{2}-\left\Vert w_{t}-w_{*}\right\Vert ^{2}\right]
\end{align*}

\end_inset

where we multiplied the second condition by 
\begin_inset Formula $\left(-1\right)$
\end_inset

.
 We now add the two inequalities to obtain
\begin_inset Formula 
\begin{align*}
F\left(w_{t+1}\right)-F\left(w_{*}\right) & \leq-\frac{L}{2}\left\Vert w_{t+1}-w_{t}\right\Vert ^{2}-\frac{L}{2}\left\Vert w_{t+1}-w_{*}\right\Vert ^{2}+\frac{L}{2}\left\Vert w_{t}-w_{t+1}\right\Vert ^{2}+\frac{L}{2}\left\Vert w_{t}-w_{*}\right\Vert ^{2}\\
 & =-\frac{L}{2}\left\Vert w_{t+1}-w_{*}\right\Vert ^{2}+\frac{L}{2}\left\Vert w_{t}-w_{*}\right\Vert ^{2}\\
 & =+\frac{L}{2}\left(\left\Vert w_{t}-w_{*}\right\Vert ^{2}-\left\Vert w_{t+1}-w_{*}\right\Vert ^{2}\right)
\end{align*}

\end_inset

From here, we proceed by computing telescoping sums.
 To do that, we sum over 
\begin_inset Formula $t=1,\cdots,T$
\end_inset

 as follows
\begin_inset Formula 
\begin{align*}
\sum_{t=1}^{T}F\left(w_{t+1}\right)-TF\left(w_{*}\right) & \leq\frac{L}{2}\left(\left\Vert w_{1}-w_{*}\right\Vert ^{2}-\left\Vert w_{t+1}-w_{*}\right\Vert ^{2}\right)\\
 & \leq\frac{L}{2}\left\Vert w_{1}-w_{*}\right\Vert ^{2}
\end{align*}

\end_inset

since 
\begin_inset Formula $\left\Vert w_{t+1}-w_{*}\right\Vert ^{2}\geq0$
\end_inset

.
 Rearranging,
\begin_inset Formula 
\[
\sum_{t=1}^{T}F\left(w_{t+1}\right)-TF\left(w_{*}\right)\leq\frac{L}{2}\left\Vert w_{1}-w_{*}\right\Vert ^{2}
\]

\end_inset

Recall that 
\begin_inset Formula $F\left(w_{t+1}\right)\leq F\left(w_{t}\right)$
\end_inset

 for each 
\begin_inset Formula $t$
\end_inset

, so that as 
\begin_inset Formula $t$
\end_inset

 increases each iteration, 
\begin_inset Formula $F$
\end_inset

 is at least non-increasing.
 Then, fixing 
\begin_inset Formula $T$
\end_inset

, we have that for all 
\begin_inset Formula $t\leq T$
\end_inset

, we have 
\begin_inset Formula $F\left(w_{T+1}\right)\leq F\left(w_{t}\right)$
\end_inset

.
 Hence, we can give an even lower bound
\begin_inset Formula 
\[
TF\left(w_{T+1}\right)-TF\left(w_{*}\right)\leq\sum_{t=1}^{T}F\left(w_{t+1}\right)-TF\left(w_{*}\right)\leq\frac{L}{2}\left\Vert w_{1}-w_{*}\right\Vert ^{2}
\]

\end_inset

Thus in the end we get
\begin_inset Formula 
\[
F\left(w_{T+1}\right)-F\left(w_{*}\right)\leq\frac{L}{2T}\left\Vert w_{1}-w_{*}\right\Vert ^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
In the case of 
\begin_inset Formula $\mu$
\end_inset

-strong convexity and L-smoothness, we can get even better results (check
 notes).
 
\end_layout

\begin_layout Standard
Smoothness makes sure you're not overshooting.
 Convexity ensures that you get to the solution.
\end_layout

\begin_layout Subsection
February 8, 2024 - Linear Regression, Logistic Regression
\end_layout

\begin_layout Standard
Recall that the gradient descent applies to general algorithms.
 In particular, we haven't really specified what the objective function
 is, or what are hypothesis class is.
 Today, we first link it to the perceptron algorithm, and then generalize
 to different models.
\end_layout

\begin_layout Paragraph
Quick Recap: Perceptron.
\end_layout

\begin_layout Standard
Recall our previous setting for the perceptron algorithm: inputs 
\begin_inset Formula $x\in\mathcal{X}=\mathbb{R}^{d}$
\end_inset

, labels 
\begin_inset Formula $y\in\mathcal{Y}=\left\{ -1,+1\right\} $
\end_inset

, hypothesis class 
\begin_inset Formula $x\mapsto\text{sign}\left(w^{\top}x+b\right)$
\end_inset

, loss: 
\begin_inset Formula $l\left(\hat{y},y\right)=0$
\end_inset

 if 
\begin_inset Formula $\hat{y}=y$
\end_inset

, else 1.
 (
\begin_inset Quotes eld
\end_inset

0/1 loss
\begin_inset Quotes erd
\end_inset

).
\end_layout

\begin_layout Paragraph
Logistic Regression.
\end_layout

\begin_layout Standard
Instead of mapping to 
\begin_inset Formula $\pm1$
\end_inset

, we could map to the continuous interval 
\begin_inset Formula $\left[0,1\right]$
\end_inset

 as a way to estimate probabilities: 
\begin_inset Formula $x\mapsto\text{Pr}\left(\left.y=1\right|x\right)\in\left[0,1\right]$
\end_inset

.
 Previously, we used the 
\begin_inset Formula $\text{sgn}\left(\cdot\right)$
\end_inset

 function.
 Now we can use the 
\series bold
squashing function
\series default

\begin_inset Formula 
\[
\sigma\left(\cdot\right):\mathbb{R}\rightarrow\left[0,1\right]
\]

\end_inset

resulting in the new hypothesis class
\begin_inset Formula 
\[
x\mapsto\sigma\left(w^{\top}x+b\right)\in\left[0,1\right]
\]

\end_inset

To be more specific, we will be using the 
\series bold
sigmoid function
\series default
 that is defined as 
\begin_inset Formula 
\[
\sigma\left(v\right)\coloneqq\frac{1}{1+e^{-v}}
\]

\end_inset

note that
\end_layout

\begin_layout Itemize
\begin_inset Formula $\lim_{v\rightarrow-\infty}\sigma\left(v\right)=0$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\sigma\left(0\right)=1/2$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\lim_{v\rightarrow\infty}\sigma\left(v\right)=1$
\end_inset


\end_layout

\begin_layout Standard
We could multiply this by a constant to steepen or flatten the function.
 The steeper it is, harder it is for the gradient descent algorithm to converge.
\end_layout

\begin_layout Standard
One reason to do this (rather than the perceptron) would be to make our
 function continuous, so that we could apply the gradient descent method.
 Another reason is to handle the noise in the data.
 Recall that the perceptron algorithm assumes that the data is perfectly
 separable, which may not hold in many cases.
 This way, we can interpret the output as a probability, and handle cases
 where things are not perfectly separable.
\end_layout

\begin_layout Paragraph
Logistic Loss Function.
\end_layout

\begin_layout Standard
Note that we can no longer use the 0/1 loss, since that will output a loss
 of 1, unless your predicted value is exactly equal to the label (i.e.
 
\begin_inset Formula $\hat{y}=y$
\end_inset

).
 Our output of the sigmoid function will never be exactly 0 or 1  this
 will only happen in the limit.
 So we need another function.
\end_layout

\begin_layout Standard
We will use something called the 
\series bold
logistic loss 
\series default
as
\begin_inset Formula 
\[
l\left(\hat{y},y\right)=\begin{cases}
-\log\left(\hat{y}\right) & \text{if }y=1\\
-\log\left(1-\hat{y}\right) & \text{if }y=-1
\end{cases}
\]

\end_inset

The logistic loss is an upper bound on the 0/1 loss when graphed on the
 
\begin_inset Formula $l\left(\hat{y},y\right)$
\end_inset

 and 
\begin_inset Formula $y\cdot w^{\top}x$
\end_inset

 space.
\end_layout

\begin_layout Standard
Let's try to understand what this function does.
 Our predicted values are restricted to the interval 
\begin_inset Formula $\hat{y}\in\left[0,1\right]$
\end_inset

.
 First, suppose 
\begin_inset Formula $y=1$
\end_inset

.
 In the correct case where 
\begin_inset Formula $\hat{y}$
\end_inset

 is almost 1, then this loss will be zero; if it is instead we are very
 wrong and 
\begin_inset Formula $\hat{y}$
\end_inset

 is almost 0, then this loss will be tending to 
\begin_inset Formula $+\infty$
\end_inset

.
 Second, let's say the correct label is 
\begin_inset Formula $y=0$
\end_inset

.
 Then if 
\begin_inset Formula $\hat{y}$
\end_inset

 is also close to zero, then 
\begin_inset Formula $-\log\left(1-\hat{y}\right)\approx0$
\end_inset

 as well.
 If 
\begin_inset Formula $\hat{y}\rightarrow1$
\end_inset

, then 
\begin_inset Formula $-\log\left(1-\hat{y}\right)\rightarrow+\infty$
\end_inset

.
 
\end_layout

\begin_layout Standard
In general, we would like this loss function to (i) be larger when we are
 wrong; and (ii) be smaller when we are closer to being correct.
\end_layout

\begin_layout Standard
An equivalent way to state this would be
\begin_inset Formula 
\[
l\left(h\left(x\right),y\right)=\log\left(1+\exp\left(-y\cdot w^{\top}x\right)\right)
\]

\end_inset

The whole goal of this is to frame this so that you are maximizing the probabili
ty of your data.
\end_layout

\begin_layout Paragraph
Probabilistic Perspective.
\end_layout

\begin_layout Standard
In general, we can take two routes in machine learning: (1) Pick a loss
 function, and just minimize that loss; or (2) Formulate a probability distribut
ion, and then maximize the probability of seeing my data.
 Sometimes the two are equivalent, which is going to be the case today.
 But not always.
\end_layout

\begin_layout Paragraph
Checking the Logistic Loss.
\end_layout

\begin_layout Standard
Let us consider each case, and confirm that the loss function we wrote down
 is actually equiavalent.
 
\end_layout

\begin_layout Standard
First, let's say 
\begin_inset Formula $y=1$
\end_inset

.
 Then,
\begin_inset Formula 
\begin{align*}
-\log\left(\hat{y}\right) & =-\log\left(\left(1+e^{-w^{\top}x}\right)^{-1}\right)\\
 & =\log\left(1+e^{-w^{\top}x}\right)\\
 & =l\left(h\left(x\right),1\right)
\end{align*}

\end_inset

Second, if 
\begin_inset Formula $y=-1$
\end_inset

, then
\begin_inset Formula 
\begin{align*}
-\log\left(1-\hat{y}\right) & =-\log\left(1-\frac{1}{1+e^{-w^{\top}x}}\right)\\
 & =-\log\left(\frac{e^{-w^{\top}x}}{1+e^{-w^{\top}x}}\right)\\
 & =\log\left(\frac{1+e^{-w^{\top}x}}{e^{-w^{\top}x}}\right)\\
 & =\log\left(1+e^{w^{\top}x}\right)\\
 & =l\left(h\left(x\right),-1\right)
\end{align*}

\end_inset

So this confirms our previous claim.
 
\end_layout

\begin_layout Paragraph
Maximum Likelihood.
\end_layout

\begin_layout Standard
Let us denote 
\begin_inset Formula $\mathcal{L}$
\end_inset

 the likelihood function, 
\begin_inset Formula $S$
\end_inset

 the sample of the dataset, and 
\begin_inset Formula $\theta$
\end_inset

 the parameters.
 Then,
\begin_inset Formula 
\begin{align*}
\mathcal{L}\left(\theta\right) & =P\left(\left.S\right|\theta\right)\\
 & =\prod_{i=1}^{m}P\left(\left.x_{i},y_{i}\right|\theta\right) & \text{iid assumption}\\
 & =\prod_{i=1}^{m}P\left(\left.y_{i}\right|x_{i},\theta\right)\cdot P\left(\left.x_{i}\right|\theta\right)
\end{align*}

\end_inset

Given some sample 
\begin_inset Formula $S$
\end_inset

, we want to maximize our probability of observing it.
 Hence the 
\series bold
maximum likelihood estimator 
\series default

\begin_inset Formula $\theta$
\end_inset

 is given by the 
\begin_inset Formula $\theta$
\end_inset

 that solves the following:
\begin_inset Formula 
\[
\max_{\theta}\mathcal{L}\left(\theta\right)
\]

\end_inset

The argmax of the above is equivalent to the argmax of the log-likelihood,
 which is 
\begin_inset Formula 
\begin{align*}
\max_{\theta}\log\mathcal{L}\left(\theta\right) & =\max_{\theta}\sum_{i=1}^{m}\left[\log P\left(\left.y_{i}\right|x_{i},\theta\right)+P\left(\left.x_{i}\right|\theta\right)\right]
\end{align*}

\end_inset


\end_layout

\begin_layout Paragraph
MLE in Logistic Regression.
\end_layout

\begin_layout Standard
In the logistic regression case we have that 
\begin_inset Formula $P\left(\left.y_{i}\right|x_{i},\theta\right)=\sigma\left(w^{\top}x+b\right)$
\end_inset

 and 
\begin_inset Formula $\theta=\left(w,b\right)$
\end_inset

.
 Assume that 
\begin_inset Formula $P\left(\left.x_{i}\right|\theta\right)$
\end_inset

 is constant.
 Then,
\begin_inset Formula 
\begin{align*}
\max_{\theta}\log\mathcal{L}\left(\theta\right) & =\log\prod_{i=1}^{m}\frac{1}{1+\exp\left(-y\cdot w^{\top}x\right)}\\
 & =-\sum_{i=1}^{m}\log\left(1+\exp\left(-y\cdot w^{\top}x\right)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Week 5
\end_layout

\begin_layout Subsection
February 13, 2024 - Linear Regression, Logistic Regression
\end_layout

\begin_layout Subsection
February 15, 2024 - Linear Support Vector Machines
\end_layout

\begin_layout Section
Week 6
\end_layout

\begin_layout Subsection
February 20, 2024 - Nonlinear Modeling, Kernels
\end_layout

\begin_layout Subsection
February 22, 2024 - Kernels, Kernel SVMs
\end_layout

\begin_layout Section
Week 7
\end_layout

\begin_layout Subsection
February 27 - Midterm
\end_layout

\begin_layout Subsection
February 29 - TBD
\end_layout

\begin_layout Section
Week 8
\end_layout

\begin_layout Subsection
March 5 - Spring Break
\end_layout

\begin_layout Subsection
March 7 - Spring Break
\end_layout

\begin_layout Section
Week 9
\end_layout

\begin_layout Subsection
March 12 - Neural Networks I
\end_layout

\begin_layout Subsection
March 14 - Neural Networks II
\end_layout

\end_body
\end_document
